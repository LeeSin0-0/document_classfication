## 1.什么是事务呢？

> 事务一般指的是逻辑上的一组操作，或者单个逻辑单元执行的一系列操作。这些操作要么执行成功，要么执行失败。
>
> 同时事务包含ACID四大特性。
>
> 1. A（Atomic）原子性：操作要么成功，要么失败。
> 2. C（Consistency）一致性：指执行之前和执行之后，数据始终处于一致的状态。
> 3. I（Isolation）隔离性：指并发执行的两个事务之间互不干扰。
> 4. D（Durability）持久性：指事务提交完成后，此事务对数据的更改操作会被持久化到数据库中，并且不会回滚。

## 2.分布式事务和事务有啥区别？

> 分布式事务指将海量数据分散的存储到多台服务器的多台数据库中，同时要具备ACID特性。
>
> 分布式事务支持CAP理论和Base理论

## 3.CAP理论可以介绍一下吗？

> C（Consistency）一致性：对所有的数据副本在进行增删查操作时，要么全部执行成功，要么全部执行失败。
>
> A（Availability）可用性：指客户端访问数据的时候，能够快速得到响应。所有的请求都会被响应，不会存在响应超时或响应错误情况，如果对不同应用程序设置超时响应时间，一旦超过这个时间，系统将不可用。
>
> P（PartitionTolerance）分区容忍性：一个节点挂掉后，不影响其他节点对外提供服务。
>
> 在分布式系统中，不会同时具备CAP三个特性，只能具备其中的两个。

## 4.那Base理论呢？

> Base理论是对CAP理论中AP理论的一个扩展，它通过牺牲强一致性来获得可用性。
>
> Base理论是基本可用（BasicallyAvailable）、软状态（SoftState）、和最终一致性（EventuallyConsistent）的缩写。当系统出现故障时，Base理论允许部分数据不可用，但是会保证核心功能能用；允许数据在一段时间内不一致，但是经过一段时间，数据最终是一致的。

## 5.在大数据组件中，你们一般用的资源管理框架是哪个？

> 更多的使用Yarn作为资源管理工具，现在一大部分业务也上云了，使用的K8S。

## 6.那你能谈一下yarn的基础架构及调度流程吗？

> yarn的基础架构主要包含3大组件，分别为ResourceManager、ApplicationMaster、NodeManager.
>
> 其中：
>
> **ResourceManager**是一个全局的资源管理器，负责整个系统的**资源管理和分配**，主要包括两个组件，即调度器（Scheduler）和应用程序管理器（ApplicationsManager）。
>
> **ApplicationMaster**：ApplicationMaster是ResourceManager根据接收用户提交的作业，按照作业的上下文信息等分配出一个container资源，然后通知NodeManager为用户作业创建出一个ApplicationMaster。
>
> **NodeManager**：NodeManager管理YARN集群中的每个节点，对节点进行资源监控和健康状态管理。
>
> **yarn的调度流程简单总结如下：**
>
> 1. 客户端提交应用程序给ResourceManager
> 2. ResouceManager收到请求后，将分配Container资源，并通知对应的NodeManager启动一个ApplicationMaster。
> 3. applicationMaster来运行和管理container里面的任务，其中container会通过心跳机制向applicationMaster来发送运行信息。
> 4. 任务完成之后，application向ResourceManager报告，任务完成，container进行资源释放。

## 7.Hive的工作机制了解吗?

> Hive是一个基于Hadoop的数据仓库工具，可以将结构化的数据文件映射为一个表。并提供类SQL查询功能。
>
> 其中底层计算方式是基于MapReduce来做运算，计算后的数据存储到HDFS中。
>
> 所以Hive利用HDFS存储数据，利用MapReduce查询数据，利用Mysql存储元数据。

## 8.Hivesql到MapReduce转化的流程清楚吗？

> Hive将SQL转化为MapReduce任务，整个编译过程分为以下几个阶段：
>
> `1.sql解析`。HIve通过Antlr对SQL进行词法、语法解析，生成抽象语法树ASTTree。
>
> `2.语法解析`。遍历ASTTree，抽象出查询的基本组成单元QueryBlock
>
> `3.生成逻辑执行计划`。遍历QueryBlock，翻译为执行操作树OperatorTree
>
> `4.优化逻辑执行计划`。逻辑层优化器进行OperatorTree变换，合并不必要的ReduceSinkOperator，减少shuffle数据量。
>
> `5.生成物理执行计划`。遍历OperatorTree，翻译为MapReduce任务。
>
> `6.优化物理执行计划`。物理层优化器进行MapReduce任务的变换，生成最终的执行计划。

## 9.Hiveshuffle过程清楚吗？

> Shuffle的正常意思是洗牌或弄乱。
>
> 在MapReduce框架中，shuffle是连接Map和Reduce之间的桥梁，Map的输出到Reduce中必须经过shuffle这个环节，shuffle的性能高低直接影响了整个程序的性能和吞吐量。
>
> 简单来说：Shuffle描述着数据从maptask输出到reducetask输入的这段过程。
>
> 大部分maptask与reducetask的执行是在不同的节点上。当然很多情况下Reduce执行时需要跨节点去拉取其它节点上的maptask结果。

## 10.spark中RDD的血缘关系介绍一下？

> RDD的血缘关系描述的是一个RDD如何从父RDD计算得来的。如果某个RDD丢失了，则可以根据血缘关系，从父RDD计算得来。
>
> 举个例子：如提交了一个任务，这个任务在执行过程中生成了一个完整的DAG图。那么这个DAG中的一系列处理就被称为一个血缘关系，即DAG拓扑排序的结果。
>
> 在血缘关系中，下一代的RDD依赖于上一代的RDD。B依赖于A，D依赖于C，而E依赖于B和D等。

## 11.数据倾斜是什么原因造成的，如何解决？

> 数据倾斜问题主要指shuffle过程中出现的数据倾斜问题，是由于不同的key对应的数据量不同，而导致不同task所处理的数据量不同的问题。
>
> 如何解决：可以分为以下几点。
>
> `1.空值引发的数据倾斜问题`。
>
> 当一个表中null值非常多，如果这张表进行join操作，那必然会有shuffle产生，这样所有的null值都会被分配到一个reduce中，必然产生数据倾斜。
>
> 解决办法：
>
> （1）直接不让null值参与join操作。在写sql时，直接将有null的过滤掉。（2）或者给null值随机赋值。因为null值参与shuffle时的hash结果是一样的，那么我们可以给null值随机赋值，这样它们的hash结果就不一样，就会进到不同的reduce中。
>
> `2.不同数据类型引发的数据倾斜`
>
> 比如当两张表join操作时，A表需要join的字段类型为int型，B表需要join的字段类型既包含int,又包含string类型。当进行AleftjoinB时，默认的hash操作会按照int类型的id进行分配。这时所有的string类型会被分配到同一个id下。若数据量过大，必会造成数据倾斜问题。
>
> 解决办法：
>
> 我们直接把int类型都转为string就好了，这样key字段都为string，hash时就按照string类型进行分配。
>
> `3.key数据分布不均所造成的数据倾斜`
>
> 解决办法：
>
> 单独处理倾斜key，为大数据量key添加随机数前缀，将其分散到多个任务中进行预聚合操作，然后将随机数前缀去掉，再和其他数据进行聚合操作。
>
> `4.用sortby代替orderby`
>
> 因为orderby为全局排序，会导致所有map端数据都进入一个reduce中，在数据量特别大时会长时间处于计算状态。使用sortby会启动多个reduce进行排序。
>
> `5.使用Mapjoin避免数据倾斜的手段`
>
> 允许在map阶段进行join操作，MapJoin把小表全部读入内存中，在map阶段直接拿另外一个表的数据和内存中表数据做匹配，由于在map是进行了join操作，省去了reduce运行的效率也会高很多。



## 12.问一些Flink基础，Flink提供几种时间语义，并且watermark机制介绍一下？

> Flink提供三种时间语义，即事件时间（eventtime）、摄入时间（ingestiontime）和处理时间（processingtime）
>
> WaterMark主要是用来处理数据延迟、数据丢失问题，一般和window、processingTime结合使用。
>
> 通过对window添加waterMark来处理迟到的数据。
>
> WaterMark包含两种**周期水位线**和**标点水位线**。

## 13.定期水位线和标点水位线有什么区别？应用于什么场景？

> **定期水位线**：定期水位线（PeriodicWatermark）按照固定时间间隔生成新的水位线，默认200ms。
>
> 使用场景：对迟到数据要求不是很严格的场景下使用。
>
> **标点水位线**（PunctuatedWatermark）通过数据流中**某些特殊标记事件**来触发新水位线的生成。这种方式下窗口的触发与时间无关，而是决定于**何时收到标记事件**。
>
> 使用场景：在实时性要求非常高的场景才会选择Punctuated的方式进行Watermark的生成。

## 14.标点水位线怎么触发waterMark？

> 标点水位线需要实现AssignerWithPunctuatedWatermarksAPI接口，然后重写两个方法：
>
> （1）**createTimestampAssigner**主要是从消息中提取事件时间。
>
> （2）**createWatermarkGenerator**主要是用于检查事件是否标点事件，当返回值非null并且新生成的水位线大于当前水位线，则触发窗口计算。

## 15.你说一下Flinkcheckpoint、state的底层逻辑？

> **`先介绍checkpoint`**
>
> 首先，checkpoint叫做检查点，是Flink实现容错机制的最核心功能，它能根据配置周期性的基于Stream中各个Operator的状态来生成**Snapshot**快照，从而将这些**状态数据定期持久化存储下来**，当Flink程序一旦意外崩溃时，重新运行程序时可以有选择地从这些Snapshot进行恢复。
>
> Flink的checkpoint机制原理来自“Chandy-Lamportalgorithm”算法
>
> **`再介绍state`**
>
> state一般指一个具体的Task/Operator的状态，主要是用来保存**中间的计算结果**或者**缓存数据**。
>
> state按照Flink管理还是用户管理分为：RowState(原始状态）和Managedstate(托管状态)
>
> 1. RowState由用户自行管理，**只支持字节数组**，所有状态都要转换为二进制字节数组才可以。
> 2. ManagedState由FlinkRunTime管理，支持多种数据结构，如MapList等
>
> **State按照key划分，可以分为KeyedState,OperatorState**.
>
> **keyedState**只能用在keyStream上，并且每一个key对应一个state对象，keyedState保存在StateBackend中，通过RuntimeContext访问，实现RichFunction接口，支持多种数据结构，如ListState、MapState、AggregatingState等
>
> OperatorState可以用于所有算子，但整个算子只对应一个**state**，实现CheckpointedFunction或者ListCheckpointed接口，目前只支持ListState数据结构。

## 16. 状态存储到 HDFS 中，一般会出现什么问题？

> 首先，状态存储在 HDFS 中，是基于文件型的状态存储方式。当 job 运行时所需的 State 数据会全部保存在 TaskManager 的内存中，**执行检查点的时候**，会把 State 的快照数据保存到配置的 HDFS 中。
>
> 当同一个集群的 Job 到达一定数量后，会对 HDFS 造成非常大的压力。同时读取 HDFS 中的数据会频繁进行 IO 交互，读取速度相对内存来说，慢很多。

## 17. 如果 checkpoint 设置 10s 一次，状态存储到 HDFS 中，会出现什么问题？

> 如果每隔 10s 就进行 checkpoint,假如 checkpoint 时，状态过小，而 HDFS 的块大小是以 128 M 进行划分，**往 HDFS 中写状态时**，不可能每次都把 128M 写满，所以就会出现大量的小文件。
>
> 这样会反过来影响 HDFS 读文件的效率，导致读取速度非常慢，加大 yarn 集群的负担，从而拖垮整个集群的效率。

## 18. Flink on k8s 的设计思路能描述一下吗？

> 目前将组件进行容器化已经成为当前的一个趋势，将 Flink 集群部署到 K8S 上 可以实现**资源的合理利用**,同时 k8s 是一个开源的容器集群管理系统，可以实现容器集群的 **自动化部署、自动扩缩容、维护** 等功能。
>
> 而 在 K8s 上部署 Flink 集群，主要包含以下几个步骤：
>
> **1 启动集群**
>
> 1. Flink 客户端使用 Kubectl 或者 K8s 的 Dashboard 提交 Flink 集群的资源描述文件，包含 4-5个 yaml 文件。
> 2. K8s Master 根据这些资源文件将请求分发给 Slave 节点，创建 Flink Master Deployment、TaskManager Deployment、ConfigMap、SVC 四个角色。同时初始化 Dispatcher 和 KubernetesResourceManager。并通过 K8S 服务对外暴露 Flink Master 端口。
> 3. Client 用户使用 Flink run 命令，通过指定 Flink Master 的地址，将相应任务提交上来，用户的 Jar 和 JobGrapth 会在 Flink Client 生成，通过 SVC 传给 Dispatcher。
> 4. Dispatcher 收到 JobGraph 后，会为每个作业启动一个 JobMaster,将 JobGraph 交给 JobMaster 进行调度。
> 5. JobMaster 会向 KubernetesResourceManager 申请资源，请求 Slot。
> 6. KubernetesResourceManager 从 K8S 集群分配 TaskManager。每个 TaskManager 都是具有唯一标识的 Pod。KubernetesResourceManager 会为 TaskManager 生成一份新的配置文件，里面有 Flink Master 的 service name 作为地址，保障在 Flink Master failover 后，TaskManager 仍然可以重新连接上。
> 7. K8S 集群分配一个新的 Pod 后，在上面启动 TaskManager。
> 8. TaskManager 启动后注册到 SlotManager。
> 9. SlotManager 向 TaskManager 请求 Slot。
> 10. TaskManager 提供 Slot 给 JobManager,然后任务被分配到 Slot 上运行。

## 19. 那 Flink on K8S 通信怎么处理？

> Flink on K8S 通信 包含 四种通信方式：
>
> `1. POD 内部通信。`直接通过 localhost 相互访问就可以。
>
> `2. 同节点的 POD 之间通信。` 通过默认的 docker 网桥互连容器直接通信就可。
>
> `3. 不同节点的 POD 之间通信`；通过安装 Flannel 组件，pod 的 ip 分配由 flannel 统一分配，通讯过程也是走 flannel 的网桥。
>
> `4. 外部网络与 POD 之间通信。`使用 Service 服务，通过 lable 关联到后端的 Pod 容器。
>
> Service 分配的 ip 叫 cluster ip，这是一个固定的虚拟 ip，这个 ip 只能在 k8s 集群内部使用，如果 service 需要对外提供，只能使用 Nodeport 方式映射到主机上，使用主机的 ip 和端口对外提供服务。（另外还可以使用 LoadBalance 方式，但这种方式是在 gce 这样的云环境里面使用的 ）。

## 20. xxx 平台架构是什么样的？

> 平台架构主要分为四层：分别为应用层、xxx 基础层、Flink 计算层、存储调度层。
>
> 应用层包含 WebUI、REST 方式，主要是一些操作界面等。
>
> xxx 计算层包含 应用管理、资源管理、元数据、脚本管理等核心模块。
>
> Flink 计算层 调用原生 Flink 组件、使用 yarn、K8S 等进行调度。
>
> 存储层：包含 HDFS、Hive、Kafka、Hbase、ES、CK 等。

## 21.  你们的 Kafka 的 QPS 是多少？

> 以一个具体的案例介绍：xxx ， 当时 Flink 从 Kafka source 端接入每秒 峰值为 2w 条数据。



## 22.  翻转二叉树说一下思路：

> 使用递归遍历二叉树时 （1）我们从根节点开始，递归地对树进行遍历，并从叶子节点先开始翻转。（2）如果当前遍历到的节点 root 的左右两棵子树都已经翻转，那么我们只需要交换两棵子树的位置，即可完成以 root 为根节点的整棵子树的翻转。
>
> ![图片](大数据常见问题收录(三).assets/翻转二叉树.gif)
>
> 代码实现：
>
> ```java
> class TreeNode{
>   int val;
>   TreeNode left;
>   TreeNode right;
>   TreeNode(int x) { val = x; }
> }
> 
> class Solution {
>     public TreeNode invertTree(TreeNode root) {
>         if(root == null){
>             return null;
>         }
>         TreeNode left = invertTree(root.left);
>         TreeNode right = invertTree(root.right);
>         root.left = right;
>         root.right = left;
>         return root;
>     }  
> }
> ```
>
> 

## 23. 买卖股票的最佳时机 II

> 给定一个数组 prices ，其中 prices[i] 表示股票第 i 天的价格。
>
> 在每一天，你可能会决定购买和/或出售股票。你在任何时候 最多 只能持有 一股 股票。你也可以购买它，然后在 同一天 出售。
>
> 返回 你能获得的 最大 利润 。
>
> ![image-20220303220340118](大数据常见问题收录(三).assets/image-20220303220340118.png)
>
> 解题思路：使用动态规划求解。
>
> 
>
> ```java
> class Solution {
>     public int maxProfit(int[] prices) {
>         int[] dp = new int[2];
>         // 0表示持有，1表示卖出
>         dp[0] = -prices[0];
>         dp[1] = 0;
>         for(int i = 1; i <= prices.length; i++){
>             // 前一天持有; 既然不限制交易次数，那么再次买股票时，要加上之前的收益
>             dp[0] = Math.max(dp[0], dp[1] - prices[i-1]);
>             // 前一天卖出; 或当天卖出，当天卖出，得先持有
>             dp[1] = Math.max(dp[1], dp[0] + prices[i-1]);
>         }
>         return dp[1];
>     }
> }
> ```









